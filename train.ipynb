{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.metrics import roc_curve, roc_auc_score,auc\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision.models as models\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/mnt/ssd/2023challenge/algonauts_2023_challenge_data'\n",
    "parent_submission_dir = '/mnt/ssd/2023challenge/algonauts_2023_challenge_submission'\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8个人(subject)的图片数据数量  \n",
    "train:  [9841, 9841, 9082, 8779, 9841, 9082, 9841, 8779]  \n",
    "test:   [159, 159, 293, 395, 159, 293, 159, 395]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj = 1            # 一共8个人，现在选择第一个人"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class argObj:\n",
    "  def __init__(self, data_dir, parent_submission_dir, subj):\n",
    "\n",
    "    self.subj = format(subj, '02')\n",
    "    self.data_dir = os.path.join(data_dir, 'subj'+self.subj)\n",
    "    self.parent_submission_dir = parent_submission_dir\n",
    "    self.subject_submission_dir = os.path.join(self.parent_submission_dir,\n",
    "        'subj'+self.subj)\n",
    "\n",
    "    # Create the submission directory if not existing\n",
    "    if not os.path.isdir(self.subject_submission_dir):\n",
    "        os.makedirs(self.subject_submission_dir)\n",
    "\n",
    "args = argObj(data_dir, parent_submission_dir, subj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 脑部活动向量，即真实标签  \n",
    "分为左脑和右脑 (Training stimulus images × LH/RH vertices)  \n",
    "subj=1中，左右脑活动矩阵大小为(9841, 19004)和(9841, 20544)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_dir = os.path.join(args.data_dir, 'training_split', 'training_fmri')       \n",
    "lh_fmri = np.load(os.path.join(fmri_dir, 'lh_training_fmri.npy'))\n",
    "rh_fmri = np.load(os.path.join(fmri_dir, 'rh_training_fmri.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图片数据\n",
    "例如受试者1的第一个训练图片`train-0001_nsd-00013.png`，分为两个索引:  \n",
    "1. `train-0001`  \n",
    "    此顺序是为了匹配 fMRI 训练数据集\n",
    "2. `nsd-00013`\n",
    "    对应于 73,000 张 NSD(nsd实际实验的先后顺序) 图像的 ID，即映射到 `COCO` 数据集 的图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images: 9841\n",
      "Test images: 159\n"
     ]
    }
   ],
   "source": [
    "train_img_dir  = os.path.join(args.data_dir, 'training_split', 'training_images')\n",
    "test_img_dir  = os.path.join(args.data_dir, 'test_split', 'test_images')\n",
    "\n",
    "# Create lists will all training and test image file names, sorted\n",
    "train_img_list = os.listdir(train_img_dir)\n",
    "train_img_list.sort()\n",
    "test_img_list = os.listdir(test_img_dir)\n",
    "test_img_list.sort()\n",
    "print('Training images: ' + str(len(train_img_list)))\n",
    "print('Test images: ' + str(len(test_img_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 连接图片数据和脑响应"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_classes = 2\n",
    "img_size = 224\n",
    "batch_size = 8\n",
    "epoch = 70\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor(),  \n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) \n",
    "])\n",
    "\n",
    "\n",
    "train_dataset, val_dataset = #......\n",
    "\n",
    "# Create DataLoader for training and validation sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=8)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dino模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DINOv2ViTModel(nn.Module):\n",
    "    def __init__(self, num_classes=1):  # 默认num_classes设置为1，因为线性回归是回归任务\n",
    "        super(DINOv2ViTModel, self).__init__()\n",
    "\n",
    "        # Load the pretrained DINOv2-ViT model\n",
    "        self.dinov2_vit = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14')\n",
    "\n",
    "        # Freeze all layers\n",
    "        for param in self.dinov2_vit.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Modify the classification head for your task\n",
    "        self.dinov2_vit.head = nn.Sequential(\n",
    "            nn.Linear(384, 128),  # 加一个隐藏层\n",
    "            nn.ReLU(),  # 激活函数\n",
    "            nn.Linear(128, num_classes)  # 最终输出层，num_classes设置为1\n",
    "        )\n",
    "\n",
    "        # Add a linear regression layer\n",
    "        self.linear_regression = nn.Linear(num_classes, 1)  # 线性回归输出1个值\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.dinov2_vit(x)\n",
    "        regression_output = self.linear_regression(features)\n",
    "        return regression_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#損失関数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion.to(device)\n",
    "\n",
    "#モデル定義\n",
    "model = DINOv2ViTModel(num_classes)        # 使用dinov2作为模型\n",
    "model = nn.DataParallel(model)              # 多GPU并行\n",
    "model.to(device)\n",
    "#オプティマイザ\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.1)           #每回合epoch自动修改学习率\n",
    "\n",
    "# 学习率调度器\n",
    "lr_scheduler = None\n",
    "#lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#モデルの学習\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "val_loss_list = []\n",
    "val_acc_list = []\n",
    "for i in range(epoch):\n",
    "    print('-'*5, 'Epoch [{}/{}] start'.format(i, epoch-1), '-'*5)\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    # モデルの学習モード切替\n",
    "    model.train()\n",
    "\n",
    "    # 学習データのデータローダから読み込み尽くすまでループ\n",
    "    for image, target in tqdm(train_loader):\n",
    "        # 入力、正解を GPU へ移動\n",
    "        image, target = image.to(device), target.to(device)\n",
    "        # モデルに入力を順伝播させ予測を出力\n",
    "        output = model(image).squeeze()\n",
    "        # 損失関数で予測と正解の誤差を導出\n",
    "        loss = criterion(output, target)\n",
    "        # オプティマイザの勾配0初期化処理\n",
    "        optimizer.zero_grad()\n",
    "        # 誤差をもとに誤差逆伝搬し勾配を導出\n",
    "        loss.backward()\n",
    "        # オプティマイザによる学習パラメータの更新\n",
    "        optimizer.step()\n",
    "        acc = (output.argmax(dim=1) == target).float().mean()   # 计算一个batch的平均准确率\n",
    "        epoch_accuracy += acc / len(train_loader)       # 该epoch(loader)的平均准确率\n",
    "        epoch_loss += loss / len(train_loader)\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    if lr_scheduler is not None:\n",
    "        lr_scheduler.step()     # 学习率调度器\n",
    "\n",
    "    # モデルの検証、評価モード切替\n",
    "    model.eval()\n",
    "    # 検証データのデータローダから読み込み尽くすまでループ\n",
    "    with torch.no_grad():\n",
    "        epoch_val_accuracy=0\n",
    "        epoch_val_loss = 0\n",
    "        for image, target in val_loader:\n",
    "            # 入力、正解を GPU へ移動\n",
    "            image, target = image.to(device), target.to(device)\n",
    "            # モデルに入力を順伝播させ予測を出力\n",
    "            output = model(image).squeeze()\n",
    "            # 損失関数で予測と正解の誤差や精度を導出\n",
    "            loss = criterion(output, target)\n",
    "            acc = (output.argmax(dim=1) == target).float().mean()\n",
    "            epoch_val_accuracy += acc / len(val_loader)\n",
    "            epoch_val_loss += loss / len(val_loader)\n",
    "\n",
    "\n",
    "    # 使用一个print将每个epoch的acc和loss以及lr都一起打印出来\n",
    "    print(f' train_acc: {epoch_accuracy:.4f}, train_loss: {epoch_loss:.4f},\\\n",
    "    val_acc: {epoch_val_accuracy:.4f}, val_loss: {epoch_val_loss:.4f}, LR: {lr:e}')\n",
    "    \n",
    "    train_loss_list.append(epoch_loss)\n",
    "    train_acc_list.append(epoch_accuracy)\n",
    "    val_loss_list.append(epoch_val_loss)\n",
    "    val_acc_list.append(epoch_val_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#学習曲線の描画\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "val_acc = []\n",
    "val_loss = []\n",
    "# Define x_arr (the x-axis values) as the number of epochs\n",
    "x_arr = range(1, epoch + 1)\n",
    "\n",
    "for i in range(epoch):\n",
    "  train_acc.append(train_acc_list[i].cpu().detach().numpy())\n",
    "  train_loss.append(train_loss_list[i])\n",
    "  val_acc.append(val_acc_list[i].cpu().detach().numpy())\n",
    "  val_loss.append(val_loss_list[i])\n",
    "\n",
    "# Create a figure and a set of subplots\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Plot the training and validation loss\n",
    "ax[0].plot(x_arr, train_loss, '-o', label='Train loss')\n",
    "ax[0].plot(x_arr, val_loss, '--<', label='Validation loss')\n",
    "ax[0].legend(fontsize=15)\n",
    "ax[0].set_xlabel('Epoch', size=15)\n",
    "ax[0].set_ylabel('Loss', size=15)\n",
    "\n",
    "# Plot the training and validation accuracy on the second subplot\n",
    "ax[1].plot(x_arr, train_acc, '-o', label='Train accuracy')\n",
    "ax[1].plot(x_arr, val_acc, '--<', label='Validation accuracy')\n",
    "ax[1].legend(fontsize=15)\n",
    "ax[1].set_xlabel('Epoch', size=15)\n",
    "ax[1].set_ylabel('Accuracy', size=15)\n",
    "\n",
    "\n",
    "plt.savefig(f'{save_path}/learning_curve.png')\n",
    "plt.show()\n",
    "\n",
    "# # 读取保存的图像\n",
    "# saved_image = Image.open(save_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dinov2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
